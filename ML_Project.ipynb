{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Different ConvNets Models \n",
    "## Motivation\n",
    "\n",
    "After learning Convolution Neural Network in the class, we know that Alex Net is widely used today in this area. In lab8 and its demos, we mainly use VGG16 and Xception as the model. Therefore, we think that whether we could use CNNs with different architecture models to work. That is the initial motivation of our project. In our project, we recreate three small ConvNets via reading some published papers. Each network (model) will be trained base on CIFAR-10 dataset. We will calculate the error rate of validation to judge the models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the dataset is imported. Both train and test image data should be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "y_train = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 consists of 60000 32x32 RGB images from 10 classes. 50000 images are used for training set and the other 10000 for testing set. Now we can varify the shape of x_train, y_train, x_test and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) | y_train shape: (50000, 10)\n",
      "x_test shape : (10000, 32, 32, 3) | y_test shape : (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: {} | y_train shape: {}\\nx_test shape : {} | y_test shape : {}'\n",
    "      .format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deifne a single model input because we are going to use the same input for our project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train[0,:,:,:].shape\n",
    "model_input = Input(shape=input_shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Strided-CNN-C\n",
    "\n",
    "The first model is Strided-CNN-C \\[[Springenberg et al., 2015, Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806)\\]. This model in which max-pooling is removed and the stride of the convolution layers preceding the max-pool layers is increased by 1.\n",
    "\n",
    "The last convolutional layer `Conv2D(10, (1, 1))` outputs 10 feature maps corresponding to ten output classes. Then the `GlobalAveragePooling2D()` layer computes spatial average of these 10 feature maps, which means that its output is just a vector with a lenght 10. After that, a softmax activation is applied to that vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strided_cnn(model_input):\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "        \n",
    "    model = Model(model_input, x, name='strided_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strided_cnn_model = strided_cnn(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to list this model's layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 954,730\n",
      "Trainable params: 954,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "strided_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using epochs with a batch size of 32 (1250 steps per epoch) to get to some local minima. Randomly chose 1/5 of the training dataset for validation. We use Adam as the optimizer. Moreover, we defined that all the epoch results should be stored in 'weights' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_and_train(model, num_epochs): \n",
    "    \n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['acc']) \n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True,\n",
    "                                                 save_best_only=True, mode='auto', period=1)\n",
    "    tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
    "    history = model.fit(x=x_train, y=y_train, batch_size=32, \n",
    "                     epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 50,000 images to be trained and 10,000 to be test, we will use Tesla K80 GPU. To save time, we set the number of epochs as 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 44s - loss: 1.7792 - acc: 0.3275 - val_loss: 1.4677 - val_acc: 0.4646\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 42s - loss: 1.2909 - acc: 0.5289 - val_loss: 1.1535 - val_acc: 0.5842\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 42s - loss: 1.0420 - acc: 0.6268 - val_loss: 0.9693 - val_acc: 0.6518\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.8844 - acc: 0.6873 - val_loss: 0.8501 - val_acc: 0.6994\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.7534 - acc: 0.7369 - val_loss: 0.8039 - val_acc: 0.7198\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.6514 - acc: 0.7712 - val_loss: 0.7193 - val_acc: 0.7501\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.5575 - acc: 0.8057 - val_loss: 0.6974 - val_acc: 0.7651\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.4716 - acc: 0.8371 - val_loss: 0.7094 - val_acc: 0.7635\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.3960 - acc: 0.8622 - val_loss: 0.7542 - val_acc: 0.7622\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.3213 - acc: 0.8871 - val_loss: 0.7927 - val_acc: 0.7636\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.2520 - acc: 0.9110 - val_loss: 0.7683 - val_acc: 0.7733\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.2003 - acc: 0.9293 - val_loss: 0.8685 - val_acc: 0.7644\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.1622 - acc: 0.9430 - val_loss: 0.9607 - val_acc: 0.7653\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.1427 - acc: 0.9511 - val_loss: 0.9943 - val_acc: 0.7614\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.1222 - acc: 0.9563 - val_loss: 1.0671 - val_acc: 0.7660\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.1074 - acc: 0.9624 - val_loss: 1.1221 - val_acc: 0.7692\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.0924 - acc: 0.9673 - val_loss: 1.1635 - val_acc: 0.7730\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.0897 - acc: 0.9697 - val_loss: 1.2158 - val_acc: 0.7677\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.0892 - acc: 0.9698 - val_loss: 1.1767 - val_acc: 0.7608\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 42s - loss: 0.0807 - acc: 0.9727 - val_loss: 1.2752 - val_acc: 0.7576\n"
     ]
    }
   ],
   "source": [
    "_ = compile_and_train(strided_cnn_model, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_error(model):\n",
    "    pred = model.predict(x_test, batch_size = 32)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
    "    error = np.sum(np.not_equal(pred, y_test)) / y_test.shape[0]    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate this model, we are gonna calculate the error rate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25629999999999997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_error(strided_cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: ConvPool-CNN-C\n",
    "\n",
    "The second model that we are going to use is ConvPool-CNN-C \\[[Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units](https://arxiv.org/pdf/1603.05201)\\]. This model composed of convolution and pooling followed by ReLU without fully connected layers. \n",
    "\n",
    "This model is pretty straightforward since It has clearly outlined network architecture only with convolution, pooling, and ReLU. It features a common pattern where several convolutional layers are followed by a pooling layer.  Instead of using several fully-connected layers, a global average pooling layer is used as the final layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_pool_cnn(model_input):\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='conv_pool_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we list the layers of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 192)       166080    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 15, 15, 192)       331968    \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 15, 15, 192)       331968    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 192)         37056     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_pool_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using K80 GPU to train data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 98s - loss: 1.7727 - acc: 0.3333 - val_loss: 1.4771 - val_acc: 0.4557\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 97s - loss: 1.2789 - acc: 0.5369 - val_loss: 1.1009 - val_acc: 0.6039\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 97s - loss: 1.0134 - acc: 0.6408 - val_loss: 0.9214 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.8544 - acc: 0.6983 - val_loss: 0.8982 - val_acc: 0.6949\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.7323 - acc: 0.7432 - val_loss: 0.7953 - val_acc: 0.7238\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.6299 - acc: 0.7813 - val_loss: 0.7426 - val_acc: 0.7480\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.5504 - acc: 0.8074 - val_loss: 0.6922 - val_acc: 0.7632\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.4802 - acc: 0.8324 - val_loss: 0.6968 - val_acc: 0.7741\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.4216 - acc: 0.8537 - val_loss: 0.7859 - val_acc: 0.7637\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.3639 - acc: 0.8731 - val_loss: 0.7038 - val_acc: 0.7873\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.3157 - acc: 0.8866 - val_loss: 0.7680 - val_acc: 0.7810\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.2695 - acc: 0.9034 - val_loss: 0.8199 - val_acc: 0.7661\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.2360 - acc: 0.9155 - val_loss: 0.8277 - val_acc: 0.7752\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.2037 - acc: 0.9265 - val_loss: 0.8316 - val_acc: 0.7774\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.1869 - acc: 0.9332 - val_loss: 0.9040 - val_acc: 0.7798\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.1595 - acc: 0.9439 - val_loss: 0.8950 - val_acc: 0.7842\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.1537 - acc: 0.9449 - val_loss: 1.0681 - val_acc: 0.7744\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.1534 - acc: 0.9462 - val_loss: 0.9484 - val_acc: 0.7828\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.1373 - acc: 0.9521 - val_loss: 1.0308 - val_acc: 0.7778\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 97s - loss: 0.1287 - acc: 0.9553 - val_loss: 1.1746 - val_acc: 0.7752\n"
     ]
    }
   ],
   "source": [
    "_ = compile_and_train(conv_pool_cnn_model, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22070000000000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_error(conv_pool_cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: ALL-CNN-C\n",
    "\n",
    "Next, we use ALL-CNN-C which also comes from the paper \\[[Springenberg et al., 2015, Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806)\\]. This model is similar to the previous one. The only difference is that convolutional layers with a stride of 2 are used in place of max pooling layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_cnn(model_input):\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "        \n",
    "    model = Model(model_input, x, name='all_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cnn_model = all_cnn(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same, we are going to list the layers of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K80 GPU used here, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 78s - loss: 1.8410 - acc: 0.2958 - val_loss: 1.5999 - val_acc: 0.3954\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 78s - loss: 1.4305 - acc: 0.4730 - val_loss: 1.2414 - val_acc: 0.5444\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 78s - loss: 1.1814 - acc: 0.5727 - val_loss: 1.0412 - val_acc: 0.6323\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.9895 - acc: 0.6444 - val_loss: 0.9309 - val_acc: 0.6714\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.8384 - acc: 0.7030 - val_loss: 0.8540 - val_acc: 0.6987\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.7223 - acc: 0.7466 - val_loss: 0.7843 - val_acc: 0.7284\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.6154 - acc: 0.7833 - val_loss: 0.7780 - val_acc: 0.7355\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.5220 - acc: 0.8178 - val_loss: 0.7200 - val_acc: 0.7526\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.4350 - acc: 0.8481 - val_loss: 0.8049 - val_acc: 0.7468\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.3510 - acc: 0.8775 - val_loss: 0.8324 - val_acc: 0.7442\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.2795 - acc: 0.9011 - val_loss: 0.9180 - val_acc: 0.7419\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.2255 - acc: 0.9199 - val_loss: 1.0313 - val_acc: 0.7539\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.1910 - acc: 0.9333 - val_loss: 1.0296 - val_acc: 0.7495\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.1546 - acc: 0.9451 - val_loss: 1.0333 - val_acc: 0.7565\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.1397 - acc: 0.9502 - val_loss: 1.1242 - val_acc: 0.7530\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.1280 - acc: 0.9552 - val_loss: 1.1518 - val_acc: 0.7634\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.1228 - acc: 0.9572 - val_loss: 1.2151 - val_acc: 0.7439\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.1196 - acc: 0.9584 - val_loss: 1.1765 - val_acc: 0.7531\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.1069 - acc: 0.9632 - val_loss: 1.2793 - val_acc: 0.7534\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 78s - loss: 0.0990 - acc: 0.9661 - val_loss: 1.3541 - val_acc: 0.7489\n"
     ]
    }
   ],
   "source": [
    "_ = compile_and_train(all_cnn_model, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26079999999999998"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_error(all_cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Network In Network CNN\n",
    "\n",
    "The last CNN we will use is Network in Network CNN \\[[Lin et al., 2013, Network In Network](https://arxiv.org/abs/1312.4400)\\]. It uses three multilayer pereceptions with 'relu' activation. The overall structure of NIN is stacking multiple mlpconv layers. Instead of adopting the traditional fully connected layers for classification in CNN, NIN directly output the spatial average of the feature maps from the last mlpconv layer as the confidence of categories via a global average pooling layer, and then the resulting vector is fed into the softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nin_cnn(model_input):\n",
    "    \n",
    "    # multilayer perception 1\n",
    "    x = Conv2D(32, (5, 5), activation='relu',padding='valid')(model_input)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # multilayer perception 2\n",
    "    x = Conv2D(64, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    #multilayer perception 3\n",
    "    x = Conv2D(128, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='nin_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nin_cnn_model = nin_cnn(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us output the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 32)        1056      \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 28, 28, 32)        1056      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 12, 12, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 12, 12, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 4, 4, 10)          330       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 109,674\n",
      "Trainable params: 109,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nin_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this model contains less trainable parameters than previous three models from the model summary above. therefore, we come out a conclusion that this model is smaller so that the training time should be less than previous two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 21s - loss: 1.9511 - acc: 0.2659 - val_loss: 1.6663 - val_acc: 0.3852\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.6233 - acc: 0.4010 - val_loss: 1.5117 - val_acc: 0.4517\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.5002 - acc: 0.4523 - val_loss: 1.4022 - val_acc: 0.4893\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.4217 - acc: 0.4802 - val_loss: 1.3690 - val_acc: 0.5002\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.3638 - acc: 0.5043 - val_loss: 1.2979 - val_acc: 0.5282\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.3139 - acc: 0.5253 - val_loss: 1.2768 - val_acc: 0.5384\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.2741 - acc: 0.5399 - val_loss: 1.1916 - val_acc: 0.5752\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.2348 - acc: 0.5544 - val_loss: 1.2090 - val_acc: 0.5642\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.2024 - acc: 0.5714 - val_loss: 1.2079 - val_acc: 0.5754\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.1761 - acc: 0.5770 - val_loss: 1.0800 - val_acc: 0.6158\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.1442 - acc: 0.5933 - val_loss: 1.0808 - val_acc: 0.6152\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.1186 - acc: 0.6013 - val_loss: 1.0555 - val_acc: 0.6255\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.0999 - acc: 0.6061 - val_loss: 1.0343 - val_acc: 0.6325\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.0873 - acc: 0.6146 - val_loss: 1.0207 - val_acc: 0.6413\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.0714 - acc: 0.6199 - val_loss: 1.0014 - val_acc: 0.6420\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.0493 - acc: 0.6272 - val_loss: 0.9767 - val_acc: 0.6525\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.0337 - acc: 0.6313 - val_loss: 0.9608 - val_acc: 0.6634\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.0217 - acc: 0.6370 - val_loss: 0.9727 - val_acc: 0.6537\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 20s - loss: 1.0092 - acc: 0.6435 - val_loss: 0.9490 - val_acc: 0.6666\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 20s - loss: 0.9944 - acc: 0.6485 - val_loss: 0.9873 - val_acc: 0.6473\n"
     ]
    }
   ],
   "source": [
    "_ = compile_and_train(nin_cnn_model, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate should be a bit higher than the other three since it is simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3543"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_error(nin_cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement\n",
    "\n",
    "We find that the error rate of these four models are higher than our expectation. Therefore, we come out an idea to combine them together to see whether the combination of them could reduce the error rate. It is called 'ensembling' in statistics. Here, we load the weights with each best one that saved in the 'weights' file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strided_cnn_model = strided_cnn(model_input)\n",
    "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
    "all_cnn_model = all_cnn(model_input)\n",
    "nin_cnn_model = nin_cnn(model_input)\n",
    "\n",
    "strided_cnn_model.load_weights('weights/strided_cnn.19-0.08.hdf5')\n",
    "conv_pool_cnn_model.load_weights('weights/conv_pool_cnn.29-0.10.hdf5')\n",
    "all_cnn_model.load_weights('weights/all_cnn.30-0.08.hdf5')\n",
    "nin_cnn_model.load_weights('weights/nin_cnn.30-0.93.hdf5')\n",
    "\n",
    "models = [strided_cnn_model, conv_pool_cnn_model, all_cnn_model, nin_cnn_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses the same input layer which is shared between all previous models. In the top layer, the combine model computes the average of three models' outputs by using `Average()` merge layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine(models, model_input):\n",
    "    \n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "    \n",
    "    model = Model(model_input, y, name='combine')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine_model = combine(models, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to output the list of combination layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, 28, 28, 32)    2432        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 28, 28, 32)    1056        conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 32, 32, 96)    2688        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 28, 28, 32)    1056        conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 32, 32, 96)    83040       conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D)  (None, 14, 14, 32)    0           conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 32, 32, 96)    83040       conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, 32, 32, 96)    2688        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 14, 14, 32)    0           max_pooling2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)   (None, 15, 15, 96)    0           conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 32, 32, 96)    83040       conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 12, 12, 64)    18496       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, 32, 32, 96)    2688        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, 15, 15, 192)   166080      max_pooling2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 16, 16, 96)    83040       conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 12, 12, 64)    4160        conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, 16, 16, 96)    83040       conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, 15, 15, 192)   331968      conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 16, 16, 192)   166080      conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 12, 12, 64)    4160        conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, 16, 16, 192)   166080      conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, 15, 15, 192)   331968      conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 16, 16, 192)   331968      conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D)  (None, 6, 6, 64)      0           conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, 8, 8, 192)     331968      conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D)  (None, 7, 7, 192)     0           conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 8, 8, 192)     331968      conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 6, 6, 64)      0           max_pooling2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, 8, 8, 192)     331968      conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, 7, 7, 192)     331968      max_pooling2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 8, 8, 192)     331968      conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 4, 4, 128)     73856       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, 8, 8, 192)     37056       conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, 7, 7, 192)     37056       conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 8, 8, 192)     37056       conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 4, 4, 32)      4128        conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 8, 8, 10)      1930        conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, 7, 7, 10)      1930        conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 8, 8, 10)      1930        conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 4, 4, 10)      330         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glob (None, 10)            0           conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Glo (None, 10)            0           conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Glo (None, 10)            0           conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Glo (None, 10)            0           conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 10)            0           global_average_pooling2d_9[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 10)            0           global_average_pooling2d_10[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 10)            0           global_average_pooling2d_11[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 10)            0           global_average_pooling2d_12[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "average_1 (Average)              (None, 10)            0           activation_9[0][0]               \n",
      "                                                                   activation_10[0][0]              \n",
      "                                                                   activation_11[0][0]              \n",
      "                                                                   activation_12[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 3,803,880\n",
      "Trainable params: 3,803,880\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combine_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print out the error rate to see whether the combination of models will work or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1915"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_error(combine_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "The models we mensioned above cannot provide better accuracy though we combine them together. But it is a good try to develop CNNs with different theorems from each paper. There should be more complicated models that could get perfectly performance. We will keep learning the CNN and find the better models. Besides, We only simply stacked the models but there should be a better way to combine them which could get lower error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
